Between Tuesday 6:00 and Thursday 18:00 (European Time) the hackathon was carried out on 20 virtual machines provided by the Dalhousie University. After many deliberations, we decided against a parallel, high intensity, short term challenge (e.g., 12 hours of continuous efforts) and activated a set of independent, middle intensity, middle length challenges (60 hours of on/off efforts).

We received 10 participants (7 from Italy, 3 from Canada) some of which carried out the tasks with intensity, some others abandoned the tasks after a few tries. At the end of the hackathon we performed interviews and obtained data from 7 different individuals.

Overall, none of the participants were able to identify security holes in our prototype architecture. This can be attributed to one or more of the following causes:

1. There are in fact no security holes in our prototype. As much as we would like for this to be true, we fear that this is highly unlikely.
2. The conditions we gave to the participants were too limiting. In particular, we gave them access as normal users to the virtual machines, and no direct access to the files constituting our dataset and blockchains, simulating therefore the setting of an "external hacker", with no privileged access to the data of the NIPs. Possibly, an "inside hacker" that penetrated one of the NIPS (either by using a hacked privileged access or by making use of a corrupted official of the NIP) could gather more information and be able to break the code. We did not test this option and some of us fear that this is where our security holes actually could be.
3. The amount of time given was too limited (and possibly the prizes were too low for the amount of effort required). There are complex operations involved in our contracts that require time, and being able to exploit security holes in them may require more time than allowed. For this reason we have decided to continue the hackathon with a low intensity, long term attitude, by publishing the docker images of the machines made available to the past hackathon, with more access (not just as normal users but root users, too) and more time (until end of February 2026 or even more). We shall also discuss increasing the amount of the prizes to make participation more interesting.
4. The amount of provided documentation was too small / too confusing / of little use. Participants had access to 100% of our code, but only with internal comments, a short introduction to the purpose of the hackathon and no real introduction to the complexity of our algorithms. Although this is a reasonably plausible context for real hackers, we fear that it could have been overwhelming for many of our participants. For this reason we will review the provided documentation with better and step-by-step introduction to our code.

As specified, seven of our participants also left some reflections on the AAA architecture, which were treated as interviews and counted for that task as well.

So, in a way, the hackathon was a success (no bugs were found) but also an open question mark (did thet look form bugs hard enough). We hoe that through the long Hackathon initiative we shall be able to know more about the quality of our tools.
